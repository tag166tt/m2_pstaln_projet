{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import regex as re\n",
    "from sklearn.model_selection import train_test_split\n",
    "def extract_full_sentences(file_path,test_size = None,shuffle = None, pos = False):\n",
    "    username = r'(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9-_]+)'\n",
    "    random_state = 42\n",
    "    X = []\n",
    "    y = []\n",
    "    temp_X = []\n",
    "    temp_y = []\n",
    "    with open(file_path, 'r', encoding=\"utf8\") as fin :\n",
    "        for l in fin :\n",
    "            l = l.rstrip().split(\"\\t\")\n",
    "            if l != [\"\"]:\n",
    "                if pos :\n",
    "                    temp_X.append(f\"{re.sub(username, 'USR', l[1].lower())}_{l[3]}\")\n",
    "                else :\n",
    "                    temp_X.append(f\"{re.sub(username, 'USR', l[1].lower())}\")\n",
    "                temp_y.append(l[7])\n",
    "            else :\n",
    "                X.append(temp_X)\n",
    "                temp_X = []\n",
    "                y.append(temp_y)\n",
    "                temp_y = []\n",
    "\n",
    "    X.append(temp_X)\n",
    "    y.append(temp_y)\n",
    "    if test_size is not None:\n",
    "        X, X_val, y, y_val = train_test_split(X, y, test_size=test_size, random_state=random_state, shuffle=shuffle)\n",
    "        return X, X_val, y, y_val\n",
    "\n",
    "    else :\n",
    "        return X,y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def write_data(X_test, y_test, filename):\n",
    "\t#xi_test format: num, word, lem, POS\n",
    "\twith open(filename, 'w', encoding='utf-8') as f:\n",
    "\t\tis_first = True\n",
    "\t\tfor xi_test, yi_test in zip(X_test, y_test):\n",
    "\t\t\tif (not is_first) and xi_test[0] == 1:\n",
    "\t\t\t\tf.write('\\n')\n",
    "\t\t\tf.write(f'{xi_test[0]}\\t{xi_test[1]}\\t-\\t{xi_test[3]}\\tO\\t0\\t\\t{yi_test}\\n')\n",
    "\t\t\tis_first = False\n",
    "\t\tf.write('\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class SstDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings,labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://github.com/soutsios/pos-tagger-bert/blob/master/pos_tagger_bert.ipynb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "POS = True pour intégrer les POS dans l'entrainement et l'inférence du modèle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "POS = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the_DET', 'night_NOUN', 'that_PRON', 'jam_PROPN', 'master_PROPN', \"jay's_PROPN\", 'hand_NOUN', 'slipped_VERB', '!_PUNCT', 'analysis_NOUN', 'by_ADP', 'cosmo_PROPN', 'baker_PROPN', ':_PUNCT', 'url_X']\n",
      "['', 'n.time', '', 'n.body', '', '', '', 'v.motion', '', 'n.act', '', 'n.person', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = extract_full_sentences('../dimsum-data-1.5/dimsum16.train',0.15,True,pos=POS)\n",
    "print(X_train[0])\n",
    "print(y_train[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TAGS:  42\n"
     ]
    }
   ],
   "source": [
    "tags = set([item for sublist in y_train for item in sublist])\n",
    "print('TOTAL TAGS: ', len(tags))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "tag2int = {}\n",
    "int2tag = {}\n",
    "\n",
    "for i, tag in enumerate(sorted(tags)):\n",
    "    tag2int[tag] = i\n",
    "    int2tag[i] = tag"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def map_tagging(y):\n",
    "    temp_y = []\n",
    "    for sentence in y :\n",
    "        temp_y.append([tag2int[tag] for tag in sentence])\n",
    "    return temp_y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "y_train = map_tagging(y_train)\n",
    "y_val = map_tagging(y_val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 70\n",
    "EPOCHS = 30"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.hist([len(s) for s in X_train], bins=50)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(X,y):\n",
    "    tokenized_inputs = tokenizer(X, padding=True, truncation=True, max_length = 35, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(y):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    return tokenized_inputs, labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "tokenized_train, padded_label_train = tokenize_and_align_labels(X_train,y_train)\n",
    "tokenized_val, padded_label_val = tokenize_and_align_labels(X_val,y_val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding(num_tokens=35, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "[-100, 0, 0, 0, 26, 26, 26, 0, 0, 0, 0, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 36, 36, 36, 0, 0, 0, -100]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_train[0])\n",
    "print(padded_label_train[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "train_dataset = SstDataset(tokenized_train,padded_label_train)\n",
    "val_dataset = SstDataset(tokenized_val,padded_label_val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForTokenClassification: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=len(tags))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_12epochs_batch64_pos\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=12,\n",
    "    weight_decay=0.01,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 4085\n",
      "  Num Epochs = 12\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 768\n",
      "C:\\Users\\eliea\\anaconda3\\envs\\dataoutai\\lib\\site-packages\\transformers\\data\\data_collator.py:317: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sequence_length = torch.tensor(batch[\"input_ids\"]).shape[1]\n",
      "C:\\Users\\eliea\\anaconda3\\envs\\dataoutai\\lib\\site-packages\\transformers\\data\\data_collator.py:328: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='768' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  2/768 : < :, Epoch 0.02/12]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 721\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 721\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 721\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 721\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 721\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 721\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 721\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results_12epochs_batch64_pos\\checkpoint-500\n",
      "Configuration saved in ./results_12epochs_batch64_pos\\checkpoint-500\\config.json\n",
      "Model weights saved in ./results_12epochs_batch64_pos\\checkpoint-500\\pytorch_model.bin\n",
      "tokenizer config file saved in ./results_12epochs_batch64_pos\\checkpoint-500\\tokenizer_config.json\n",
      "Special tokens file saved in ./results_12epochs_batch64_pos\\checkpoint-500\\special_tokens_map.json\n",
      "C:\\Users\\eliea\\anaconda3\\envs\\dataoutai\\lib\\site-packages\\transformers\\data\\data_collator.py:317: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sequence_length = torch.tensor(batch[\"input_ids\"]).shape[1]\n",
      "C:\\Users\\eliea\\anaconda3\\envs\\dataoutai\\lib\\site-packages\\transformers\\data\\data_collator.py:328: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 721\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 721\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 721\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 721\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 721\n",
      "  Batch size = 64\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=768, training_loss=0.5181901355584463, metrics={'train_runtime': 246.0998, 'train_samples_per_second': 199.187, 'train_steps_per_second': 3.121, 'total_flos': 438132125617200.0, 'train_loss': 0.5181901355584463, 'epoch': 12.0})"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Default batch_size was 16 for both eval and train\n",
    "\n",
    "For 12 epochs :\n",
    "    TrainOutput(global_step=3072, training_loss=0.3117038222650687, metrics={'train_runtime': 647.8535, 'train_samples_per_second': 75.665, 'train_steps_per_second': 4.742, 'total_flos': 1139143526604720.0, 'train_loss': 0.3117038222650687, 'epoch': 12.0})\n",
    "\n",
    "for 12 epochs with batch_size=64 :\n",
    "    TrainOutput(global_step=768, training_loss=0.5313298602898916, metrics={'train_runtime': 554.7323, 'train_samples_per_second': 88.367, 'train_steps_per_second': 1.384, 'total_flos': 1139143526604720.0, 'train_loss': 0.5313298602898916, 'epoch': 12.0})\n",
    "\n",
    "for 12 epochs with batch_size=64 and POS :\n",
    "    TrainOutput(global_step=768, training_loss=0.5026372075080872, metrics={'train_runtime': 243.8739, 'train_samples_per_second': 201.006, 'train_steps_per_second': 3.149, 'total_flos': 438132125617200.0, 'train_loss': 0.5026372075080872, 'epoch': 12.0})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "nerpipeline = pipeline('ner', model=model, tokenizer=tokenizer, device = 0, aggregation_strategy ='simple')\n",
    "text = \"usr i hear enough talking, just turn round keep walking ahaha\"\n",
    "pred = nerpipeline(text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'LABEL_0', 'score': 0.7907538, 'word': 'usr i hear enough talking, just turn round keep walking ahaha', 'start': 0, 'end': 61}]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usr i hear enough talking, just turn round keep walking ahaha\n"
     ]
    }
   ],
   "source": [
    "for token in pred :\n",
    "    word = token['word']\n",
    "    pred_sst = int2tag[int(token['entity_group'].split(\"_\")[1])]\n",
    "    print(f\"{word}\", end =\"\")\n",
    "    if pred_sst != \"\":\n",
    "        print(f\" : {pred_sst}\")\n",
    "    else :\n",
    "        print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def decode_pred(X_test,pred):\n",
    "    y = []\n",
    "    i = 0\n",
    "    for token in pred :\n",
    "        # print(X_test[i])\n",
    "        # print(token)\n",
    "        pred_sst = int2tag[int(token['entity_group'].split(\"_\")[1])]\n",
    "\n",
    "        while i < len(X_test) and X_test[i].lower() in token['word'] :\n",
    "            y.append(pred_sst)\n",
    "            i+=1\n",
    "\n",
    "    return y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eliea\\anaconda3\\envs\\dataoutai\\lib\\site-packages\\transformers\\pipelines\\base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = extract_full_sentences('../dimsum-data-1.5/dimsum16.test',pos=POS)\n",
    "if POS :\n",
    "    X_allign, _ = extract_full_sentences('../dimsum-data-1.5/dimsum16.test')\n",
    "else :\n",
    "    X_allign = X_test\n",
    "\n",
    "y_pred = []\n",
    "for sentence,sentence_wo_pos in zip(X_test,X_allign) :\n",
    "    # print(sentence)\n",
    "    pred = decode_pred(sentence_wo_pos,nerpipeline(' '.join(sentence)))\n",
    "    # print(' '.join(sentence))\n",
    "    y_pred.append(pred)\n",
    "    # print(pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['USR_X', 'i_PRON', 'hear_VERB', 'enough_ADV', 'talking_VERB', ',_PUNCT', 'just_ADV', 'turn_VERB', 'round_ADV', 'keep_VERB', 'walking_VERB', 'haha_INTJ', 'in_ADP', 'that_DET', 'part_NOUN']\n",
      "{'input_ids': [[101, 2149, 2099, 1035, 1060, 102], [101, 1045, 1035, 4013, 2078, 102], [101, 2963, 1035, 12034, 102], [101, 2438, 1035, 4748, 2615, 102], [101, 3331, 1035, 12034, 102], [101, 1010, 1035, 26136, 6593, 102], [101, 2074, 1035, 4748, 2615, 102], [101, 2735, 1035, 12034, 102], [101, 2461, 1035, 4748, 2615, 102], [101, 2562, 1035, 12034, 102], [101, 3788, 1035, 12034, 102], [101, 5292, 3270, 1035, 20014, 3501, 102], [101, 1999, 1035, 4748, 2361, 102], [101, 2008, 1035, 20010, 102], [101, 2112, 1035, 15156, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1]]}\n",
      "['', '', 'v.communication', '', 'v.communication', '', '', 'v.motion', '', 'v.stative', 'v.motion', '', '', '', 'n.quantity']\n"
     ]
    }
   ],
   "source": [
    "print(X_test[0])\n",
    "print(tokenizer(X_test[0]))\n",
    "print(y_pred[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USR_X\n",
      "i_PRON\n",
      "hear_VERB |pred :v.communication|gold :v.perception \n",
      "enough_ADV\n",
      "talking_VERB |pred :v.communication|gold :v.communication \n",
      ",_PUNCT\n",
      "just_ADV\n",
      "turn_VERB |pred :v.motion|gold :v.motion \n",
      "round_ADV\n",
      "keep_VERB |pred :v.stative|gold :v.stative \n",
      "walking_VERB |pred :v.motion|gold :v.motion \n",
      "haha_INTJ\n",
      "in_ADP\n",
      "that_DET\n",
      "part_NOUN |pred :n.quantity|gold :n.location \n"
     ]
    }
   ],
   "source": [
    "for sentence, pred, gold in zip(X_test,y_pred,y_test):\n",
    "    for word, pred_tag, gold_tag in zip(sentence, pred, gold):\n",
    "        print(f\"{word}\", end =\"\")\n",
    "        if pred_tag != \"\" or gold_tag != \"\" :\n",
    "            print(f\" | pred :{pred_tag}| gold :{gold_tag} \")\n",
    "        else :\n",
    "            print()\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fuck_VERB', '\\ue139_PRON']\n"
     ]
    }
   ],
   "source": [
    "print(X_test[133])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Un cas un peu bizarre à cause d'un caractére spécial"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "nerpipeline(' '.join(X_test[133]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'entity_group': 'LABEL_0',\n  'score': 0.59910697,\n  'word': 'fuck _ verb _ pron',\n  'start': 0,\n  'end': 16}]"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['']\n"
     ]
    }
   ],
   "source": [
    "print(y_pred[133])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(X_test))\n",
    "print(len(y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def write_pred(gold_file,y_pred,post  = \"\"):\n",
    "    i = 0\n",
    "    j = 0\n",
    "    with open(gold_file, 'r', encoding='utf-8') as f_gold :\n",
    "        with open(f\"{'.'.join(gold_file.split('.')[:-1])}.{post}.pred\", 'w', encoding='utf-8') as f_pred :\n",
    "            for line in f_gold:\n",
    "                line = line.rstrip().split(\"\\t\")\n",
    "                if line != [\"\"] :\n",
    "                    # print(f\"i : {i}\")\n",
    "                    # print(f\"j : {j}\")\n",
    "                    # print(y_pred[i])\n",
    "                    if j >= len(y_pred[i]): #Pour les cas ??????????????\n",
    "                        pred = \"\"\n",
    "                    else :\n",
    "                        pred = y_pred[i][j]\n",
    "\n",
    "                    line[7] = pred\n",
    "                    line[4] = \"O\" #Car on n'a pas prédit les MWEs\n",
    "                    line[5] = \"0\" #Car on n'a pas prédit les MWEs\n",
    "                    j+=1\n",
    "                if line == [\"\"] :\n",
    "                    i+=1\n",
    "                    j=0\n",
    "                f_pred.write('\\t'.join(line))\n",
    "                f_pred.write('\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "write_pred(\"../dimsum-data-1.5/dimsum16.test\",y_pred,\"12epochs_batch_size64_pos\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}