{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import collections\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchcrf import CRF\n",
    "from sklearn import preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y+[\"<eos>\"])\n",
    "int_labels = le.transform(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "max_len = 16\n",
    "batch_size = 64\n",
    "embed_size = 300 # modifier paramètre uniquement si vous utilisez d'autres embeddings pré-entraînés\n",
    "hidden_size = 128"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51507\n",
      "[237]\n"
     ]
    }
   ],
   "source": [
    "le_vocab = preprocessing.LabelEncoder()\n",
    "vocab = [text for _, text, _, _ in X]+[\"<eos>\"]\n",
    "\n",
    "int_texts = le_vocab.fit_transform(vocab)\n",
    "print(len(int_texts))\n",
    "print(le_vocab.transform([\".\"]))\n",
    "temp_x = []\n",
    "final_x = []\n",
    "temp_y = []\n",
    "final_y = []\n",
    "\n",
    "dot_symbol = le_vocab.transform([\".\"])\n",
    "for x,y in zip(int_texts,int_labels) :\n",
    "\ttemp_x.append(x)\n",
    "\ttemp_y.append(y)\n",
    "\tif x == dot_symbol :\n",
    "\t\tfinal_x.append(temp_x)\n",
    "\t\tfinal_y.append(temp_y)\n",
    "\t\ttemp_x = []\n",
    "\t\ttemp_y = []\n",
    "\n",
    "int_texts = final_x\n",
    "int_labels = final_y\n",
    "# print(le_vocab.inverse_transform(final_x[0]))\n",
    "# print(le.inverse_transform(final_y[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3829, 4540, 8669, 4203, 8133, 4444, 6777, 3987, 6415, 4399, 3844, 7195,\n",
      "        7930,  237,    0,    0])\n",
      "tensor([ 0, 17,  0,  0, 40,  0,  0,  0, 36,  0,  0,  0, 12,  0,  0,  0])\n",
      "['' 'n.person' '' '' 'v.social' '' '' '' 'v.emotion' '' '' '' 'n.group' ''\n",
      " '' '']\n"
     ]
    }
   ],
   "source": [
    "X = torch.zeros(len(int_texts), max_len).long()\n",
    "Y = torch.zeros(len(int_labels), max_len).long()\n",
    "for i, (text, label) in enumerate(zip(int_texts, int_labels)):\n",
    "\tlength = min(max_len, len(text))\n",
    "\tX[i,:length] = torch.LongTensor(text[:length])\n",
    "\tY[i,:length] = torch.LongTensor(label[:length])\n",
    "print(X[12])\n",
    "print(Y[12])\n",
    "print(le.inverse_transform(Y[12]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# pretrained_weights = torch.zeros(len(vocab), 300)\n",
    "# with open('wiki-news-300d-1M.vec', encoding=\"utf-8\") as fp:\n",
    "# \tfp.readline()\n",
    "# \tfor line in fp:\n",
    "# \t\ttokens = line.strip().split()\n",
    "# \t\tif tokens[0].lower() in le_vocab.classes_:\n",
    "# \t\t\tpretrained_weights[le_vocab.transform([tokens[0].lower()])] = torch.FloatTensor([float(x) for x in tokens[1:]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "import pickle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# with open(f\"pretrained_weights.pkl\", 'wb') as fo:\n",
    "# \tpickle.dump(pretrained_weights, fo)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "with open(f\"pretrained_weights.pkl\", 'rb') as fin:\n",
    "\tpretrained_weights = pickle.load(fin)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3829, 4540, 8669, 4203, 8133, 4444, 6777, 3987, 6415, 4399, 3844, 7195,\n",
      "        7930,  237,    0,    0])\n",
      "tensor([ 0, 17,  0,  0, 40,  0,  0,  0, 36,  0,  0,  0, 12,  0,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "X = torch.zeros(len(int_texts), max_len).long()\n",
    "Y = torch.zeros(len(int_labels), max_len).long()\n",
    "\n",
    "for i, (text, label) in enumerate(zip(int_texts, int_labels)):\n",
    "    length = min(max_len, len(text))\n",
    "    X[i,:length] = torch.LongTensor(text[:length])\n",
    "    Y[i,:length] = torch.LongTensor(label[:length])\n",
    "\n",
    "print(X[12])\n",
    "print(Y[12])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "X_train = X[:2000]\n",
    "Y_train = Y[:2000]\n",
    "X_valid = X[2000:]\n",
    "Y_valid = Y[2000:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "train_set = TensorDataset(X_train, Y_train)\n",
    "valid_set = TensorDataset(X_valid, Y_valid)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "RNN(\n  (embed): Embedding(8802, 300, padding_idx=463)\n  (rnn): GRU(300, 128, bias=False, batch_first=True)\n  (dropout): Dropout(p=0.3, inplace=False)\n  (decision): Linear(in_features=128, out_features=8802, bias=True)\n)"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, pretrained_weights, le):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(len(le.classes_), embed_size, padding_idx=le.transform(['<eos>'])[0])\n",
    "        self.embed.weight = nn.Parameter(pretrained_weights, requires_grad=False)\n",
    "        self.rnn = nn.GRU(embed_size, hidden_size, bias=False, num_layers=1, bidirectional=False, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.decision = nn.Linear(hidden_size * 1 * 1, len(le.classes_))\n",
    "\n",
    "    def forward(self, x):\n",
    "        embed = self.embed(x)\n",
    "        output, hidden = self.rnn(embed)\n",
    "        return self.decision(self.dropout(output))\n",
    "\n",
    "rnn_model = RNN(pretrained_weights, le_vocab)\n",
    "rnn_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 16, 8802])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  print(rnn_model(X[:2]).shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.15382562442259354, 0.0013422818791946308)"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def perf(model, loader):\n",
    "\tcriterion = nn.CrossEntropyLoss()\n",
    "\tmodel.eval()\n",
    "\ttotal_loss = correct = num_loss = num_perf = 0\n",
    "\tfor x, y in loader:\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\ty_scores = model(x)\n",
    "\t\t\tloss = criterion(y_scores.view(y.size(0) * y.size(1), -1), y.view(y.size(0) * y.size(1)))\n",
    "\t\t\ty_pred = torch.max(y_scores, 2)[1]\n",
    "\t\t\tmask = (y != 0)\n",
    "\t\t\tcorrect += torch.sum((y_pred.data == y) * mask)\n",
    "\t\t\ttotal_loss += loss.item()\n",
    "\t\t\tnum_loss += len(y)\n",
    "\t\t\tnum_perf += torch.sum(mask).item()\n",
    "\treturn total_loss / num_loss, correct.item() / num_perf\n",
    "\n",
    "perf(rnn_model, valid_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.09984938430786133 0.04736312952908603 0.0013422818791946308\n",
      "1 0.03997862148284912 0.03957474367185072 0.020134228187919462\n",
      "2 0.036693758964538574 0.037675662474198776 0.020134228187919462\n",
      "3 0.034983372688293456 0.03594202480532906 0.020134228187919462\n",
      "4 0.03353504294157028 0.03448308056051081 0.020134228187919462\n",
      "5 0.032256755411624906 0.03332324867898768 0.020134228187919462\n",
      "6 0.03126042276620865 0.0323540446433154 0.022818791946308724\n",
      "7 0.030422228276729583 0.03162022476846522 0.022818791946308724\n",
      "8 0.02986017894744873 0.031027098948305302 0.022818791946308724\n",
      "9 0.029344615221023558 0.030538424172184685 0.022818791946308724\n",
      "10 0.028907779097557068 0.030145177109674973 0.025503355704697986\n",
      "11 0.02874341952800751 0.029790567403489895 0.032214765100671144\n",
      "12 0.028331458508968354 0.029467047615484757 0.022818791946308724\n",
      "13 0.02798076754808426 0.029168578711423008 0.06308724832214765\n",
      "14 0.02771499103307724 0.02888127551837401 0.053691275167785234\n",
      "15 0.027479027926921844 0.02864347736943852 0.08322147651006712\n",
      "16 0.027291563093662263 0.028381088240580124 0.0912751677852349\n",
      "17 0.02699683290719986 0.02816111594438553 0.06711409395973154\n",
      "18 0.02680836546421051 0.02797688679261641 0.07919463087248323\n",
      "19 0.02672638267278671 0.027755489403551274 0.08859060402684564\n",
      "20 0.026464774549007416 0.027567739513787357 0.10335570469798658\n",
      "21 0.02638025915622711 0.027332908727905968 0.10738255033557047\n",
      "22 0.02611758691072464 0.027138374745845795 0.11677852348993288\n",
      "23 0.02585337245464325 0.02694486826658249 0.11812080536912752\n",
      "24 0.025725446224212647 0.02675602381879633 0.13288590604026845\n",
      "25 0.025529545068740844 0.026627125387842007 0.138255033557047\n",
      "26 0.025435072004795074 0.026471096006306736 0.14093959731543623\n",
      "27 0.025242663443088533 0.026306530291383915 0.13691275167785236\n",
      "28 0.025225705027580262 0.02612180466001684 0.15033557046979865\n",
      "29 0.025066361308097838 0.025952854617075485 0.16644295302013423\n",
      "30 0.024881880700588225 0.025768637657165527 0.18389261744966443\n",
      "31 0.024767529785633086 0.02563443441282619 0.19463087248322147\n",
      "32 0.02460911375284195 0.025466994128443977 0.21208053691275167\n",
      "33 0.024446174204349518 0.025333901020613583 0.23221476510067113\n",
      "34 0.024414480805397033 0.025197061625393955 0.23758389261744967\n",
      "35 0.02422345507144928 0.02506971223787828 0.22818791946308725\n",
      "36 0.02402854013442993 0.024919468570839275 0.23221476510067113\n",
      "37 0.023990218341350556 0.02474544400518591 0.23624161073825503\n",
      "38 0.023692697048187255 0.02455613762140274 0.2563758389261745\n",
      "39 0.02356362646818161 0.024454581466588108 0.25906040268456376\n",
      "40 0.023537225186824797 0.024324799125844784 0.2536912751677852\n",
      "41 0.023476766228675842 0.024199861694465984 0.2657718120805369\n",
      "42 0.023261975646018982 0.02405646578832106 0.2697986577181208\n",
      "43 0.02306750100851059 0.023931566287170757 0.27114093959731544\n",
      "44 0.023018570482730864 0.023811274631456894 0.27248322147651005\n",
      "45 0.022824346959590913 0.023659684441306374 0.2644295302013423\n",
      "46 0.022812149882316588 0.02352591739459471 0.2912751677852349\n",
      "47 0.02259177714586258 0.023419111289761284 0.2791946308724832\n",
      "48 0.022636292219161986 0.02327225086363879 0.2832214765100671\n",
      "49 0.02239843714237213 0.023138328032060104 0.28187919463087246\n"
     ]
    }
   ],
   "source": [
    "def fit(model, epochs, train_loader, valid_loader):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(filter(lambda param: param.requires_grad, model.parameters()))\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = num = 0\n",
    "        for x, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_scores = model(x)\n",
    "            loss = criterion(y_scores.view(y.size(0) * y.size(1), -1), y.view(y.size(0) * y.size(1)))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            num += len(y)\n",
    "        print(epoch, total_loss / num, *perf(model, valid_loader))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.022305285155773163 0.023033688014203853 0.287248322147651\n",
      "1 0.02211806446313858 0.022806393151933498 0.29261744966442954\n",
      "2 0.021842821419239045 0.022621241482821377 0.29261744966442954\n",
      "3 0.02176356518268585 0.02246382561596957 0.2912751677852349\n",
      "4 0.021542116284370423 0.022251335057345303 0.29395973154362415\n",
      "5 0.021307790517807006 0.022029705345630646 0.3073825503355705\n",
      "6 0.020948788225650786 0.02179977094585245 0.31140939597315437\n",
      "7 0.02084458488225937 0.021584784442728214 0.32483221476510066\n",
      "8 0.020576954782009126 0.02137730744752017 0.3275167785234899\n",
      "9 0.020259391009807587 0.021165002476085316 0.3288590604026846\n",
      "10 0.02005208510160446 0.020928542045029728 0.338255033557047\n",
      "11 0.01984624046087265 0.020745701410553673 0.3476510067114094\n",
      "12 0.019616094946861267 0.020571653138507496 0.3422818791946309\n",
      "13 0.01924274468421936 0.020355243574489246 0.3704697986577181\n",
      "14 0.01902614641189575 0.02016018195585771 0.3731543624161074\n",
      "15 0.018830136954784395 0.019979444417086514 0.3731543624161074\n",
      "16 0.018558191150426864 0.019775841723788868 0.37986577181208053\n",
      "17 0.018321177661418914 0.019580106166276066 0.38926174496644295\n",
      "18 0.01810723900794983 0.01945511522618207 0.3812080536912752\n",
      "19 0.017925017952919006 0.019301044670018284 0.40268456375838924\n",
      "20 0.017643853157758713 0.019146961244669827 0.4\n",
      "21 0.01757017707824707 0.01902218366211111 0.41073825503355704\n",
      "22 0.017347486525774003 0.018866914239796726 0.4080536912751678\n",
      "23 0.017081620842218398 0.018693781711838463 0.4134228187919463\n",
      "24 0.017035069912672042 0.018635969270359386 0.4120805369127517\n",
      "25 0.016656471461057663 0.018474960191683334 0.425503355704698\n",
      "26 0.016388878792524337 0.01835539462891492 0.42013422818791946\n",
      "27 0.016366414576768875 0.018273541195826096 0.41073825503355704\n",
      "28 0.01609546795487404 0.018186315216801384 0.42013422818791946\n",
      "29 0.01594823756814003 0.01809469779784029 0.43355704697986575\n",
      "30 0.01569536426663399 0.01796377721157941 0.42013422818791946\n",
      "31 0.01562272509932518 0.017911823635751552 0.425503355704698\n",
      "32 0.015298613905906677 0.017848143184726887 0.42013422818791946\n",
      "33 0.015123044729232787 0.017787086354060608 0.4161073825503356\n",
      "34 0.01490279471874237 0.017756074328314175 0.4134228187919463\n",
      "35 0.01483640006184578 0.017698247662999413 0.42416107382550333\n",
      "36 0.014547277063131333 0.01761880009011789 0.4389261744966443\n",
      "37 0.014389608472585679 0.017553218047727238 0.425503355704698\n",
      "38 0.014214627742767334 0.01761712743477388 0.4228187919463087\n",
      "39 0.013964374423027039 0.01759005067023364 0.42013422818791946\n",
      "40 0.01389380893111229 0.01761532642624595 0.4228187919463087\n",
      "41 0.013510510385036468 0.017489328303120354 0.4348993288590604\n",
      "42 0.013251744598150253 0.017549884928898377 0.43355704697986575\n",
      "43 0.013102246820926667 0.017562460492957722 0.42818791946308726\n",
      "44 0.012882785111665726 0.01768431846391071 0.42013422818791946\n",
      "45 0.01274727565050125 0.01759442924098535 0.425503355704698\n",
      "46 0.01248424306511879 0.017702508040449837 0.4161073825503356\n",
      "47 0.01226190385222435 0.017853186211802742 0.4214765100671141\n",
      "48 0.012047692567110063 0.017801780253648758 0.4389261744966443\n",
      "49 0.011837955921888351 0.01786370778625662 0.42818791946308726\n"
     ]
    }
   ],
   "source": [
    "fit(rnn_model, 50, train_loader, valid_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}